{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.classes import Data, Particles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from codebase.file_utils import (\n",
    "    save_obj,\n",
    "    load_obj,\n",
    "    make_folder,\n",
    "    path_backslash\n",
    ")\n",
    "from codebase.ibis import essl, exp_and_normalise, model_phonebook\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 factor Sim EZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating new directory: ./log/20201207_230922_sim_ez/\n"
     ]
    }
   ],
   "source": [
    "existing_directory = None\n",
    "task_handle = 'sim_ez'\n",
    "gen_model = 0\n",
    "\n",
    "if existing_directory is None:\n",
    "    log_dir = make_folder(task_handle)  \n",
    "    print(\"\\n\\nCreating new directory: %s\" % log_dir)\n",
    "\n",
    "else:\n",
    "    log_dir = existing_directory\n",
    "    log_dir = path_backslash(log_dir)\n",
    "    print(\"\\n\\nReading from existing directory: %s\" % log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "exp_data = Data(\n",
    "    name = task_handle, \n",
    "    model_num = 4, \n",
    "    size = 100,\n",
    "    random_seed = 0\n",
    "    )\n",
    "    \n",
    "exp_data.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [54:03<00:00, 32.44s/it]\n"
     ]
    }
   ],
   "source": [
    "model_num = 1\n",
    "## setup particles\n",
    "param_names = model_phonebook(model_num)['param_names']\n",
    "latent_names = model_phonebook(model_num)['latent_names']\n",
    "particles = Particles(\n",
    "    name = 'normal',\n",
    "    model_num = model_num,\n",
    "    size = 1000,\n",
    "    param_names = param_names,\n",
    "    latent_names = latent_names)\n",
    "particles.set_log_dir(log_dir)\n",
    "if gen_model:\n",
    "    particles.compile_prior_model()\n",
    "    particles.compile_model()\n",
    "else:\n",
    "    particles.load_prior_model()\n",
    "    particles.load_model()\n",
    "\n",
    "particles.sample_prior_particles(exp_data.get_stan_data()) # sample prior particles\n",
    "particles.reset_weights() # set weights to 0\n",
    "log_lklhds = np.empty(exp_data.size)\n",
    "degeneracy_limit = 0.5\n",
    "for t in tqdm(range(exp_data.size)):\n",
    "    particles.get_incremental_weights(\n",
    "        exp_data.get_stan_data_at_t(t)\n",
    "        )\n",
    "    log_lklhds[t] =  particles.get_loglikelihood_estimate()\n",
    "    particles.update_weights()\n",
    "    \n",
    "    if (essl(particles.weights) < degeneracy_limit * particles.size) and (t+1) < exp_data.size:\n",
    "        particles.resample_particles()\n",
    "        particles.jitter(exp_data.get_stan_data_upto_t(t+1))\n",
    "        particles.reset_weights()\n",
    "    else:\n",
    "        particles.update_weights()\n",
    "\n",
    "    save_obj(particles, 'particles', log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Marginal Likelihood 0.08616\n",
      "\n",
      "\n",
      "Estimate\n",
      "[-0.   -0.05  0.1   0.   -0.01 -0.  ]\n",
      "\n",
      "\n",
      "Estimate\n",
      "[[0.93 0.54 0.49 0.11 0.13 0.1 ]\n",
      " [0.54 1.01 0.44 0.1  0.12 0.09]\n",
      " [0.49 0.44 1.02 0.09 0.11 0.08]\n",
      " [0.11 0.1  0.09 0.91 0.44 0.33]\n",
      " [0.13 0.12 0.11 0.44 1.09 0.39]\n",
      " [0.1  0.09 0.08 0.33 0.39 0.76]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_obj(log_lklhds, 'log_lklhds', log_dir)\n",
    "\n",
    "print('\\n\\n')\n",
    "marg_lklhd = np.exp(logsumexp(log_lklhds))\n",
    "print('Marginal Likelihood %.5f'%marg_lklhd)\n",
    "\n",
    "for name in ['alpha', 'Marg_cov']:\n",
    "    samples = np.squeeze(particles.particles[name])\n",
    "    w = exp_and_normalise(particles.weights)\n",
    "    print('\\n\\nEstimate')\n",
    "    print(np.round(np.average(samples,axis=0, weights=w),2))\n",
    "    # print('\\nRead Data')\n",
    "    # print(np.round(exp_data.raw_data[name],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08616251372582091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marg_lklhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
