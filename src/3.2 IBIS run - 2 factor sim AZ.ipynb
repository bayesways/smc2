{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.classes import Data, Particles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from codebase.file_utils import (\n",
    "    save_obj,\n",
    "    load_obj,\n",
    "    make_folder,\n",
    "    path_backslash\n",
    ")\n",
    "from codebase.ibis import essl, exp_and_normalise, model_phonebook\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 factor Sim AZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating new directory: ./log/20201217_191031_sim_az/\n"
     ]
    }
   ],
   "source": [
    "existing_directory = None\n",
    "task_handle = 'sim_az'\n",
    "gen_model = 0\n",
    "\n",
    "if existing_directory is None:\n",
    "    log_dir = make_folder(task_handle)  \n",
    "    print(\"\\n\\nCreating new directory: %s\" % log_dir)\n",
    "\n",
    "else:\n",
    "    log_dir = existing_directory\n",
    "    log_dir = path_backslash(log_dir)\n",
    "    print(\"\\n\\nReading from existing directory: %s\" % log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "exp_data = Data(\n",
    "    name = task_handle, \n",
    "    model_num = 4, \n",
    "    size = 100,\n",
    "    random_seed = 0\n",
    "    )\n",
    "    \n",
    "exp_data.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:35:06<00:00, 93.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "model_num = 3\n",
    "## setup particles\n",
    "param_names = model_phonebook(model_num)['param_names']\n",
    "latent_names = model_phonebook(model_num)['latent_names']\n",
    "particles = Particles(\n",
    "    name = 'normal',\n",
    "    model_num = model_num,\n",
    "    size = 2000,\n",
    "    param_names = param_names,\n",
    "    latent_names = latent_names)\n",
    "particles.set_log_dir(log_dir)\n",
    "if gen_model:\n",
    "    particles.compile_prior_model()\n",
    "    particles.compile_model()\n",
    "else:\n",
    "    particles.load_prior_model()\n",
    "    particles.load_model()\n",
    "\n",
    "particles.sample_prior_particles(exp_data.get_stan_data()) # sample prior particles\n",
    "particles.reset_weights() # set weights to 0\n",
    "log_lklhds = np.empty(exp_data.size)\n",
    "degeneracy_limit = 0.5\n",
    "for t in tqdm(range(exp_data.size)):\n",
    "    particles.get_incremental_weights(\n",
    "        exp_data.get_stan_data_at_t(t)\n",
    "        )\n",
    "    log_lklhds[t] =  particles.get_loglikelihood_estimate()\n",
    "    particles.update_weights()\n",
    "    \n",
    "    if (essl(particles.weights) < degeneracy_limit * particles.size) and (t+1) < exp_data.size:\n",
    "        particles.resample_particles()\n",
    "        particles.jitter(exp_data.get_stan_data_upto_t(t+1))\n",
    "        particles.reset_weights()\n",
    "    else:\n",
    "        particles.update_weights()\n",
    "\n",
    "    save_obj(particles, 'particles', log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Marginal Likelihood 0.09590\n",
      "\n",
      "\n",
      "Estimate\n",
      "[-0.06 -0.08 -0.02 -0.07 -0.08  0.  ]\n",
      "\n",
      "\n",
      "Estimate\n",
      "[[0.85 0.33 0.46 0.04 0.07 0.01]\n",
      " [0.33 0.91 0.36 0.06 0.07 0.04]\n",
      " [0.46 0.36 1.04 0.04 0.09 0.03]\n",
      " [0.04 0.06 0.04 0.96 0.41 0.42]\n",
      " [0.07 0.07 0.09 0.41 0.93 0.38]\n",
      " [0.01 0.04 0.03 0.42 0.38 1.  ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_obj(log_lklhds, 'log_lklhds', log_dir)\n",
    "\n",
    "print('\\n\\n')\n",
    "marg_lklhd = np.exp(logsumexp(log_lklhds))\n",
    "print('Marginal Likelihood %.5f'%marg_lklhd)\n",
    "\n",
    "for name in ['alpha', 'Marg_cov']:\n",
    "    samples = np.squeeze(particles.particles[name])\n",
    "    w = exp_and_normalise(particles.weights)\n",
    "    print('\\n\\nEstimate')\n",
    "    print(np.round(np.average(samples,axis=0, weights=w),2))\n",
    "    # print('\\nRead Data')\n",
    "    # print(np.round(exp_data.raw_data[name],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09589759151698887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marg_lklhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
