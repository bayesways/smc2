{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from codebase.file_utils import (\n",
    "    save_obj,\n",
    "    load_obj,\n",
    ")\n",
    "from codebase.plot import plot_density, plot_line, get_post_df\n",
    "import altair as alt\n",
    "from codebase.classes_data import Data\n",
    "from codebase.ibis import exp_and_normalise\n",
    "from run_ibis_lvm import run_ibis_lvm\n",
    "from run_mcmc import run_mcmc\n",
    "\n",
    "from codebase.file_utils import (\n",
    "    save_obj,\n",
    "    load_obj,\n",
    "    make_folder,\n",
    "    path_backslash\n",
    ")\n",
    "from pdb import set_trace\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating new directory: ./log/20210125_213734_mcmc_smc2_1/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_handle = 'mcmc_smc2_1'\n",
    "gen_model = 0\n",
    "existing_directory = None\n",
    "\n",
    "if existing_directory is None:\n",
    "    log_dir = make_folder(task_handle)  \n",
    "    print(\"\\n\\nCreating new directory: %s\" % log_dir)\n",
    "\n",
    "else:\n",
    "    log_dir = existing_directory\n",
    "    log_dir = path_backslash(log_dir)\n",
    "    print(\"\\n\\nReading from existing directory: %s\" % log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate data\n",
    "exp_data = Data(\n",
    "    name = task_handle, \n",
    "    model_num = 1,  \n",
    "    size = 100,\n",
    "    random_seed = 2\n",
    "    )\n",
    "\n",
    "exp_data.generate()\n",
    "save_obj(exp_data, 'complete_data', log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Particles from the correct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 7\n",
    "gen_model = False\n",
    "size = 500\n",
    "bundle_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "alpha = np.array([-0.53,  0.35, -1.4 , -1.4 , -0.96, -2.33])\n",
    "beta = np.array([1, 0.7, .8, .5, .9, .6])\n",
    "\n",
    "alpha_particles = multivariate_normal.rvs(mean = alpha, size=size)\n",
    "beta_particles = multivariate_normal.rvs(mean = beta, size=size).reshape((size, 6, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.classes_ibis_lvm import ParticlesLVM\n",
    "from codebase.ibis import model_phonebook, essl\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = model_phonebook(model_num)[\"param_names\"]\n",
    "latent_names = model_phonebook(model_num)[\"latent_names\"]\n",
    "jitter_corrs = dict()\n",
    "for p in param_names:\n",
    "    jitter_corrs[p] = np.zeros(exp_data.size)\n",
    "particles = ParticlesLVM(\n",
    "    name=\"ibis_lvm\",\n",
    "    model_num=model_num,\n",
    "    size=size,\n",
    "    bundle_size=bundle_size,\n",
    "    param_names=param_names,\n",
    "    latent_names=latent_names,\n",
    "    latent_model_num=1,\n",
    ")\n",
    "particles.set_log_dir(log_dir)\n",
    "if gen_model:\n",
    "    particles.compile_prior_model()\n",
    "    particles.compile_model()\n",
    "else:\n",
    "    particles.load_prior_model()\n",
    "    particles.load_model()\n",
    "\n",
    "log_lklhds = np.empty(exp_data.size)\n",
    "degeneracy_limit = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.sample_prior_particles(exp_data.get_stan_data())  # sample prior particles\n",
    "particles.particles['beta'] = beta_particles\n",
    "particles.particles['alpha'] = alpha_particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles.particles['beta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "particles.reset_weights()  # set weights to 0\n",
    "particles.initialize_bundles(exp_data.get_stan_data())\n",
    "particles.initialize_latent_var_given_theta(exp_data.get_stan_data())\n",
    "particles.initialize_counter(exp_data.get_stan_data())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [15:07<00:00, 45.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(50, 70)):\n",
    "\n",
    "    particles.sample_latent_bundle_at_t(t, exp_data.get_stan_data_at_t(t))\n",
    "    particles.get_theta_incremental_weights_at_t(t, exp_data.get_stan_data_at_t(t))\n",
    "    log_lklhds[t] = particles.get_loglikelihood_estimate()\n",
    "\n",
    "    particles.update_weights()\n",
    "\n",
    "    if (essl(particles.weights) < degeneracy_limit * particles.size) and (\n",
    "        t + 1\n",
    "    ) < exp_data.size:\n",
    "        particles.add_ess(t)\n",
    "        particles.resample_particles_bundles()\n",
    "        particles.jitter_bundles_and_pick_one(exp_data.get_stan_data_upto_t(t + 1))\n",
    "\n",
    "        ## add corr of param before jitter\n",
    "        pre_jitter = dict()\n",
    "        for p in param_names:\n",
    "            pre_jitter[p] = particles.particles[p].flatten()\n",
    "        ####\n",
    "\n",
    "        particles.jitter(t + 1, exp_data.get_stan_data_upto_t(t + 1))\n",
    "\n",
    "        ## add corr of param\n",
    "        for p in param_names:\n",
    "            jitter_corrs[p][t] = np.corrcoef(\n",
    "                pre_jitter[p], particles.particles[p].flatten()\n",
    "            )[0, 1]\n",
    "        ####\n",
    "\n",
    "        particles.reset_weights()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    save_obj(t, \"t\", log_dir)\n",
    "    save_obj(particles, \"particles\", log_dir)\n",
    "    save_obj(jitter_corrs, \"jitter_corrs\", log_dir)\n",
    "    save_obj(log_lklhds, \"log_lklhds\", log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in tqdm(range(51, 60)):\n",
    "# t = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particles.sample_latent_bundle_at_t(t, exp_data.get_stan_data_at_t(t))\n",
    "# particles.get_theta_incremental_weights_at_t(t, exp_data.get_stan_data_at_t(t))\n",
    "# log_lklhds[t] = particles.get_loglikelihood_estimate()\n",
    "\n",
    "# particles.update_weights()\n",
    "\n",
    "# if (essl(particles.weights) < degeneracy_limit * particles.size) and (\n",
    "#     t + 1\n",
    "# ) < exp_data.size:\n",
    "#     particles.add_ess(t)\n",
    "#     particles.resample_particles_bundles()\n",
    "#     particles.jitter_bundles_and_pick_one(exp_data.get_stan_data_upto_t(t + 1))\n",
    "\n",
    "#     ## add corr of param before jitter\n",
    "#     pre_jitter = dict()\n",
    "#     for p in param_names:\n",
    "#         pre_jitter[p] = particles.particles[p].flatten()\n",
    "#     ####\n",
    "\n",
    "#     particles.jitter(t + 1, exp_data.get_stan_data_upto_t(t + 1))\n",
    "\n",
    "#     ## add corr of param\n",
    "#     for p in param_names:\n",
    "#         jitter_corrs[p][t] = np.corrcoef(\n",
    "#             pre_jitter[p], particles.particles[p].flatten()\n",
    "#         )[0, 1]\n",
    "#     ####\n",
    "\n",
    "#     particles.reset_weights()\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# save_obj(t, \"t\", log_dir)\n",
    "# save_obj(particles, \"particles\", log_dir)\n",
    "# save_obj(jitter_corrs, \"jitter_corrs\", log_dir)\n",
    "# save_obj(log_lklhds, \"log_lklhds\", log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Marginal Likelihood 81.03180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\n\")\n",
    "marg_lklhd = np.exp(logsumexp(log_lklhds))\n",
    "print(\"Marginal Likelihood %.5f\" % marg_lklhd)\n",
    "save_obj(marg_lklhd, \"marg_lklhd\", log_dir)\n",
    "\n",
    "output = dict()\n",
    "output[\"particles\"] = particles\n",
    "output[\"log_lklhds\"] = log_lklhds\n",
    "output[\"marg_lklhd\"] = marg_lklhd\n",
    "output[\"jitter_corrs\"] = jitter_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = load_obj('particles', log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.resample_particles()\n",
    "ps = particles.particles.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post process loadings for sign flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = ps['beta'].shape[0]\n",
    "nrows = ps['beta'].shape[1]\n",
    "for n in range(nsim):\n",
    "    for i in range(nrows):\n",
    "        sign = np.sign(ps['beta'][n,0])\n",
    "        ps['beta'][n] = sign * ps['beta'][n,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot MCMC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a5b5eb1765304799b8d51136bccfc5c1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a5b5eb1765304799b8d51136bccfc5c1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a5b5eb1765304799b8d51136bccfc5c1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f6e0d18b786dbaf59d3e43c13b1173ac\"}, \"mark\": {\"type\": \"bar\", \"opacity\": 0.6}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"source\"}, \"column\": {\"type\": \"quantitative\", \"field\": \"col\"}, \"row\": {\"type\": \"quantitative\", \"field\": \"row\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"q1\", \"title\": null}, \"x2\": {\"field\": \"q2\", \"title\": null}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-f6e0d18b786dbaf59d3e43c13b1173ac\": [{\"row\": 0, \"col\": 0, \"q1\": 0.026270745811573612, \"q2\": 1.2489006324691734, \"source\": \"smc2\"}, {\"row\": 1, \"col\": 0, \"q1\": -0.7078892391763693, \"q2\": 1.0367925863778142, \"source\": \"smc2\"}, {\"row\": 2, \"col\": 0, \"q1\": -1.0588572093218955, \"q2\": 1.2053454566818327, \"source\": \"smc2\"}, {\"row\": 3, \"col\": 0, \"q1\": -0.9285847009850626, \"q2\": 1.0327333358777386, \"source\": \"smc2\"}, {\"row\": 4, \"col\": 0, \"q1\": -0.868227714819166, \"q2\": 1.0500852224949164, \"source\": \"smc2\"}, {\"row\": 5, \"col\": 0, \"q1\": -0.8160866442754068, \"q2\": 1.0686718046171746, \"source\": \"smc2\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = 'beta'\n",
    "df = get_post_df(ps[param])\n",
    "df_quant = df.groupby(['row', 'col'])[['value']].quantile(0.025).reset_index()\n",
    "df_quant.rename({'value':'q1'}, axis=1, inplace=True)\n",
    "df_quant2 = df.groupby(['row', 'col'])[['value']].quantile(0.975).reset_index()\n",
    "df_quant2.rename({'value':'q2'}, axis=1, inplace=True)\n",
    "\n",
    "df = df_quant.merge(df_quant2, on=['row', 'col'])\n",
    "\n",
    "# simple quantile chart\n",
    "df['source'] = 'smc2'\n",
    "c1 = alt.Chart(df).mark_bar(opacity=0.6).encode(\n",
    "        alt.X('q1', title=None),\n",
    "        alt.X2('q2', title=None),\n",
    "        alt.Row('row'),\n",
    "        alt.Column('col'),\n",
    "        alt.Color('source')\n",
    ")\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = 'r_' + df.row.astype(str)+'.c_'+df.col.astype(str)\n",
    "df = df.loc[:,['index', 'q1', 'q2', 'source']]\n",
    "\n",
    "dd = pd.DataFrame(exp_data.raw_data['beta'], columns=['data'])\n",
    "dd['col'] = 0\n",
    "dd['row'] = np.arange(6)\n",
    "dd['index'] = 'r_' + dd.row.astype(str)+'.c_'+dd.col.astype(str)\n",
    "dd = dd.loc[:,['index', 'data']]\n",
    "plot_data = df.merge(dd, on=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-1699bdc1bc7b491498dfff80049b2c23\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1699bdc1bc7b491498dfff80049b2c23\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1699bdc1bc7b491498dfff80049b2c23\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-3744705e28b18c6900d1cb8a4ea3d1e4\"}, \"facet\": {\"type\": \"nominal\", \"field\": \"index\"}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\", \"opacity\": 0.6}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"source\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"q1\", \"scale\": {\"domain\": [-2, 2]}, \"title\": null}, \"x2\": {\"field\": \"q2\", \"title\": null}}}, {\"mark\": {\"type\": \"point\", \"color\": \"red\", \"opacity\": 1}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"data\", \"title\": null}}}]}, \"columns\": 1, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-3744705e28b18c6900d1cb8a4ea3d1e4\": [{\"index\": \"r_0.c_0\", \"q1\": 0.026270745811573612, \"q2\": 1.2489006324691734, \"source\": \"smc2\", \"data\": 1.0}, {\"index\": \"r_1.c_0\", \"q1\": -0.7078892391763693, \"q2\": 1.0367925863778142, \"source\": \"smc2\", \"data\": 0.7}, {\"index\": \"r_2.c_0\", \"q1\": -1.0588572093218955, \"q2\": 1.2053454566818327, \"source\": \"smc2\", \"data\": 0.8}, {\"index\": \"r_3.c_0\", \"q1\": -0.9285847009850626, \"q2\": 1.0327333358777386, \"source\": \"smc2\", \"data\": 0.5}, {\"index\": \"r_4.c_0\", \"q1\": -0.868227714819166, \"q2\": 1.0500852224949164, \"source\": \"smc2\", \"data\": 0.9}, {\"index\": \"r_5.c_0\", \"q1\": -0.8160866442754068, \"q2\": 1.0686718046171746, \"source\": \"smc2\", \"data\": 0.6}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = alt.Chart(plot_data).mark_bar(opacity=0.6).encode(\n",
    "    alt.X('q1', title=None,  scale=alt.Scale(domain=[-2,2])),\n",
    "    alt.X2('q2', title=None),\n",
    "    alt.Color('source'),    \n",
    ")\n",
    "    \n",
    "\n",
    "c2 = alt.Chart(plot_data).mark_point(opacity=1, color='red').encode(\n",
    "        alt.X('data', title=None),\n",
    ")\n",
    "(c1+c2).facet(\n",
    "       'index',\n",
    "    columns=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
